# -*- coding: utf-8 -*-
"""
SpeakStudio (Streamlit)
- ã‚¹ãƒãƒ›äº’æ›: <audio> ã« WAV ã¨ MP3 ã‚’ä¸¡æ–¹åŸ‹ã‚è¾¼ã¿ï¼ˆãƒ–ãƒ©ã‚¦ã‚¶ãŒè‡ªå‹•é¸æŠï¼‰
- éŒ²éŸ³: é€šå¸¸ã¯ streamlit-mic-recorderã€ãƒ€ãƒ¡ãªã‚‰ WebRTC éŒ²éŸ³ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰ã«åˆ‡æ›¿
- gTTSå¼·åˆ¶ / WAVå¤‰æ› / ä»£æ›¿ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ï¼ˆHTMLç›´åŸ‹ã‚ï¼‰ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§åˆ‡æ›¿
- ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ä¾‹æ–‡ãƒ»ãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¯èª­CSSãƒ»ã‚µã‚¤ãƒ‰ãƒãƒ¼æ¡ˆå†…
"""

from __future__ import annotations
import io
import difflib
import base64
import wave
import numpy as np

import streamlit as st
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr

import constants as ct
import functions as fn

# ---------- ãƒšãƒ¼ã‚¸è¨­å®š ----------
st.set_page_config(page_title=ct.APP_NAME, page_icon="ğŸ§", layout="wide")

# ---------- CSS ----------
st.markdown("""
<style>
:root { --radius: 14px; }

/* å…±é€šãƒœãƒƒã‚¯ã‚¹ */
.block { border: 1px solid #e5e7eb; padding: 12px 14px; border-radius: var(--radius); background: #ffffff; color: #111; }
.note  { background: #f7faff; border-color: #cfe3ff; color: #111; }
.tran  { background: #fff8e6; border-color: #ffd28a; color: #111; }
small.help { color: #333; }

/* ãƒ¢ãƒã‚¤ãƒ«å‘ã‘ãƒ’ãƒ³ãƒˆï¼ˆå¹…ãŒç‹­ã„æ™‚ã ã‘è¡¨ç¤ºï¼‰ */
.mobile-tip { display:none; margin: 8px 0 12px; padding:10px 12px; border:1px dashed #6aa0ff; border-radius:12px; background:#eef5ff; color:#0b1f3a; }
@media (max-width: 768px) { .mobile-tip { display:block; } }

/* ä¾‹æ–‡ã®ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãƒœãƒƒã‚¯ã‚¹ï¼š30ä»¶ã§ã‚‚è¦‹åˆ‡ã‚Œãªã„ */
.scroll-list {
  max-height: 50vh; overflow-y: auto; padding: 8px 12px;
  border: 1px solid #e5e7eb; border-radius: 12px; background: #fff; color: #111;
}

/* ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒæ™‚ã®èª­ã¿ã‚„ã™ã•ç¢ºä¿ï¼ˆç™½åœ°ã«é»’å­—ã‚’å¼·åˆ¶ï¼‰ */
@media (prefers-color-scheme: dark) {
  .block, .note, .tran, .scroll-list { color: #111; background: #fff; border-color: #e5e7eb; }
  small.help { color: #222; }
}
</style>
""", unsafe_allow_html=True)

# ---------- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ----------
with st.sidebar:
    st.markdown(f"### {ct.APP_NAME}")

    # è¨€èªé¸æŠ
    code_list = list(ct.LANGS.keys())
    label_list = [ct.LANGS[c]["label"] for c in code_list]
    lang_idx = st.radio("ç·´ç¿’è¨€èª", options=range(len(code_list)),
                        format_func=lambda i: label_list[i],
                        index=code_list.index(ct.DEFAULT_LANG))
    lang = code_list[lang_idx]
    st.session_state["lang"] = lang

    # ãƒ¢ãƒ¼ãƒ‰é¸æŠ
    mode_map = {
        "Daily Chat": ct.ANSWER_MODE_DAILY,
        "Shadowing": ct.ANSWER_MODE_SHADOWING,
        "Roleplay": ct.ANSWER_MODE_ROLEPLAY
    }
    mode_label = st.radio("ãƒ¢ãƒ¼ãƒ‰", list(mode_map.keys()), index=0)
    mode = mode_map[mode_label]
    st.session_state["mode"] = mode

    st.divider()

    # å³æ™‚è¨³ï¼ˆéŸ“â†’æ—¥ï¼‰
    show_trans = st.checkbox("å³æ™‚è¨³ï¼ˆéŸ“â†’æ—¥ï¼‰ã‚’è¡¨ç¤º", value=True)

    # è‡ªå‹•å†ç”Ÿï¼ˆã‚¹ãƒãƒ›ã¯OFFæ¨å¥¨ï¼‰
    autoplay = st.checkbox("éŸ³å£°ã®è‡ªå‹•å†ç”Ÿï¼ˆiOSã¯OFFæ¨å¥¨ï¼‰", value=False)
    st.session_state["autoplay"] = autoplay

    # äº’æ›æ€§ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    use_alt_player = st.checkbox("ä»£æ›¿ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ï¼ˆHTMLç›´åŸ‹ã‚ï¼‰ã‚’ä½¿ã†", value=True,
                                 help="ã‚¹ãƒãƒ›ã§å†ç”Ÿã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã¯ONã€‚")
    force_gtts = st.checkbox("gTTSã‚’å¼·åˆ¶ï¼ˆäº’æ›æ€§å„ªå…ˆï¼‰", value=True,
                             help="Edge-TTSã§é³´ã‚‰ãªã„ç«¯æœ«å‘ã‘ã€‚é€Ÿåº¦èª¿æ•´ã¯ç„¡åŠ¹ã€‚")
    force_wav = st.checkbox("WAVã«å¤‰æ›ã—ã¦å†ç”Ÿï¼ˆäº’æ›æ€§å„ªå…ˆãƒ»æ¨å¥¨ï¼‰", value=True,
                            help="ffmpegåˆ©ç”¨ã€‚iOS Safari ãªã©ã§å®‰å®šã€‚")

    st.divider()

    # TTS è¨­å®šï¼ˆgTTSå¼·åˆ¶æ™‚ã¯é€Ÿåº¦/å£°ã®é¸æŠã‚’ç„¡åŠ¹åŒ–ï¼‰
    prefer_edge = st.checkbox("Edge-TTSã‚’å„ªå…ˆã™ã‚‹ï¼ˆé€Ÿåº¦èª¿æ•´å¯ï¼‰",
                              value=not force_gtts, disabled=force_gtts)
    rate = st.slider("éŸ³å£°é€Ÿåº¦ï¼ˆï¼…ï¼‰", min_value=-50, max_value=50, value=0, step=5, disabled=force_gtts)
    voices = ct.LANGS[lang].get("edge_voices", [])
    edge_voice = st.selectbox("Edge-TTSã®å£°", voices, index=0 if voices else None, disabled=force_gtts) if voices else None

    st.session_state["tts_cfg"] = {
        "prefer_edge": prefer_edge,
        "rate": rate,
        "edge_voice": edge_voice,
        "use_alt_player": use_alt_player,
        "force_gtts": force_gtts,
        "force_wav": force_wav
    }

    st.divider()
    st.markdown('<div class="block note"><small class="help">éŒ²éŸ³ã§ããªã„å ´åˆã¯ã€ŒWebRTCéŒ²éŸ³ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰ã€ã‚’ONã«ã€‚Safariã¯éŒ²éŸ³å½¢å¼ã®åˆ¶ç´„ãŒå³ã—ã„ãŸã‚ç«¯æœ«å·®ãŒå‡ºã¾ã™ã€‚</small></div>', unsafe_allow_html=True)

# ---------- ãƒ˜ãƒƒãƒ€ãƒ¼ ----------
st.markdown(f"## {ct.APP_NAME}")
st.markdown('<div class="mobile-tip">ğŸ“± ã‚¹ãƒãƒ›ã®æ–¹ã¸ï¼šå·¦ä¸Šã®<strong>â‰¡ï¼ˆãƒ¡ãƒ‹ãƒ¥ãƒ¼ï¼‰</strong>ã§ã‚µã‚¤ãƒ‰ãƒãƒ¼ãŒé–‹ãã¾ã™ã€‚</div>', unsafe_allow_html=True)
st.markdown('<div class="block note">è‹±èª / éŸ“å›½èªã®ä¼šè©±ç·´ç¿’ãƒ»ã‚·ãƒ£ãƒ‰ãƒ¼ã‚¤ãƒ³ã‚°ãƒ»ãƒ­ãƒ¼ãƒ«ãƒ—ãƒ¬ã‚¤</div>', unsafe_allow_html=True)

# ---------- å…±é€šãƒ˜ãƒ«ãƒ‘ ----------
def synth_and_player(text: str, lang_code: str, file_stub: str = "speech"):
    """
    1ã‚¯ãƒªãƒƒã‚¯ã§ MP3 ã¨ WAV ã‚’ä¸¡æ–¹ç”¨æ„ã—ã€<audio> ã«è¤‡æ•° <source> ã‚’åŸ‹ã‚è¾¼ã‚€ã€‚
    ãƒ–ãƒ©ã‚¦ã‚¶ã¯å†ç”Ÿå¯èƒ½ãªæ–¹ã‚’è‡ªå‹•é¸æŠã€‚
    """
    cfg = st.session_state.get(
        "tts_cfg",
        {"prefer_edge": False, "rate": 0, "edge_voice": None,
         "use_alt_player": True, "force_gtts": True, "force_wav": True}
    )

    # 1) MP3 ã‚’ç”Ÿæˆï¼ˆgTTSå¼·åˆ¶å¯ï¼‰
    mp3_bytes, mp3_mime = fn.tts_synthesize(
        text, lang_code=lang_code,
        rate_pct=cfg["rate"], prefer_edge=cfg["prefer_edge"],
        edge_voice=cfg["edge_voice"], force_wav=False, force_gtts=cfg["force_gtts"]
    )

    # 2) WAV ã‚’ç”Ÿæˆï¼ˆffmpeg ãŒç„¡ã„å ´åˆã¯ mp3 ã®ã¾ã¾è¿”ã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
    wav_bytes, wav_mime = fn.tts_synthesize(
        text, lang_code=lang_code,
        rate_pct=cfg["rate"], prefer_edge=cfg["prefer_edge"],
        edge_voice=cfg["edge_voice"], force_wav=cfg["force_wav"], force_gtts=cfg["force_gtts"]
    )

    # 3) ã‚½ãƒ¼ã‚¹ã‚’çµ„ã¿ç«‹ã¦ï¼ˆWAVå„ªå…ˆâ†’MP3ï¼‰
    sources: list[tuple[str, bytes]] = []
    if wav_mime == "audio/wav" and isinstance(wav_bytes, (bytes, bytearray)) and len(wav_bytes) > 44:
        sources.append((wav_mime, wav_bytes))
    if isinstance(mp3_bytes, (bytes, bytearray)) and len(mp3_bytes) > 0:
        sources.append((mp3_mime, mp3_bytes))

    if not sources:
        st.error("éŸ³å£°ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€ŒgTTSã‚’å¼·åˆ¶ã€ã€ŒWAVã«å¤‰æ›ã€ã‚’ONã«ã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    # 4) ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    if cfg.get("use_alt_player", True):
        # HTML <audio> ã«è¤‡æ•° <source> ã‚’åŸ‹ã‚è¾¼ã¿ï¼ˆplaysinline ã§ iOS å¯¾ç­–ï¼‰
        html = '<audio controls preload="metadata" playsinline>'
        for mime, data in sources:
            b64 = base64.b64encode(data).decode("ascii")
            html += f'<source src="data:{mime};base64,{b64}" type="{mime}"/>'
        html += "</audio>"
        st.markdown(html, unsafe_allow_html=True)

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆå…ˆé ­ã‚½ãƒ¼ã‚¹ï¼‰
        top_mime, top_data = sources[0]
        ext = "wav" if top_mime == "audio/wav" else "mp3"
        st.download_button(
            "â¬‡ï¸ éŸ³å£°ã‚’ä¿å­˜ï¼ˆå†ç”Ÿã§ããªã„å ´åˆï¼‰",
            top_data, file_name=f"{file_stub}.{ext}", mime=top_mime,
            use_container_width=True
        )
    else:
        # Streamlit ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã¯å˜ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã‹æ¸¡ã›ãªã„ã®ã§ WAV ã‚’å„ªå…ˆ
        mime, data = sources[0]
        st.audio(data, format=mime)

# ---- WebRTCéŒ²éŸ³ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰: ç«¯æœ«ã«ã‚ˆã£ã¦ã¯ mic_recorder ãŒå‹•ã‹ãªã„ãŸã‚ã®ä¿é™º ----
def record_audio_webrtc_once() -> bytes | None:
    try:
        from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration
        import av
    except Exception:
        st.warning("WebRTCéŒ²éŸ³ã‚’ä½¿ã†ã«ã¯ 'streamlit-webrtc' ã¨ 'av' ãŒå¿…è¦ã§ã™ï¼ˆrequirements.txt ã«è¿½åŠ ï¼‰ã€‚")
        return None

    rtc_conf = RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]})
    ctx = webrtc_streamer(
        key="webrtc_rec",
        mode=WebRtcMode.SENDONLY,  # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆâ†’ã‚µãƒ¼ãƒã¸é€ã‚‹ã ã‘
        audio_receiver_size=256,
        media_stream_constraints={"video": False, "audio": True},
        rtc_configuration=rtc_conf,
    )

    # é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ä¸€æ™‚ãƒãƒƒãƒ•ã‚¡
    if "webrtc_buf" not in st.session_state:
        st.session_state["webrtc_buf"] = []
        st.session_state["webrtc_rate"] = 48000

    col_a, col_b = st.columns(2)
    with col_a:
        st.caption("ğŸ™ï¸ WebRTCéŒ²éŸ³ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰ã‚’é–‹å§‹â†’Safariç­‰ã®éŒ²éŸ³ä¸å…·åˆã®ä¿é™º")
    with col_b:
        stop = st.button("â¹ï¸ éŒ²éŸ³ã‚’åœæ­¢ã—ã¦ä¿å­˜", use_container_width=True)

    if ctx.state.playing:
        # å—ä¿¡ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’éšæ™‚è¿½è¨˜
        frames = ctx.audio_receiver.get_frames(timeout=1)
        for f in frames:
            arr = f.to_ndarray(format="s16")  # 16bit PCM
            # arr ã® shape ã¯å®Ÿè£…ã«ã‚ˆã‚Š (channels, samples) or (samples, channels)
            if arr.ndim == 2:
                if arr.shape[0] < arr.shape[1]:  # (channels, samples)
                    mono = arr[0, :]
                else:  # (samples, channels)
                    mono = arr[:, 0]
            else:
                mono = arr
            st.session_state["webrtc_buf"].append(mono.tobytes())
            st.session_state["webrtc_rate"] = int(getattr(f, "sample_rate", 48000))

    if stop and st.session_state["webrtc_buf"]:
        # WAV ã«ã¾ã¨ã‚ã‚‹
        buf = io.BytesIO()
        with wave.open(buf, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # s16
            wf.setframerate(st.session_state["webrtc_rate"])
            wf.writeframes(b"".join(st.session_state["webrtc_buf"]))
        data = buf.getvalue()
        st.session_state["webrtc_buf"] = []
        return data

    return None

def show_translation_if_needed(source_text_ko: str):
    if st.session_state.get("lang") == "ko" and show_trans and source_text_ko.strip():
        jp = fn.translate_text(source_text_ko, target_lang_label="Japanese")
        st.markdown('<div class="block tran">ã€æ—¥æœ¬èªè¨³ã€‘<br>' + jp + '</div>', unsafe_allow_html=True)

# ========== 1) Daily Chat ==========
if st.session_state["mode"] == ct.ANSWER_MODE_DAILY:
    st.subheader("Daily Chatï¼ˆãƒ•ãƒªãƒ¼ãƒˆãƒ¼ã‚¯ï¼‰")
    st.markdown('<div class="block note">ã‚¹ãƒãƒ›ã§éŸ³ãŒå‡ºãªã„/éŒ²éŸ³ã§ããªã„å ´åˆã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®äº’æ›è¨­å®šã‚„WebRTCéŒ²éŸ³ã‚’ãŠè©¦ã—ãã ã•ã„ã€‚</div>', unsafe_allow_html=True)

    if "chat" not in st.session_state:
        st.session_state["chat"] = []

    for i, (who, text) in enumerate(st.session_state["chat"]):
        with st.chat_message(who):
            st.write(text)
            if who == "assistant":
                if st.session_state["lang"] == "ko":
                    show_translation_if_needed(text)
                if st.button("â–¶ï¸ å†ç”Ÿ", key=f"play_hist_{i}"):
                    synth_and_player(text, st.session_state["lang"], file_stub=f"reply_{i}")

    user_text = st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ï¼ˆæ—¥æœ¬èª/è‹±èª/éŸ“å›½èª OKï¼‰")
    if user_text:
        st.session_state["chat"].append(("user", user_text))
        with st.chat_message("user"):
            st.write(user_text)

        system_prompt = ct.system_prompt_for(ct.ANSWER_MODE_DAILY, st.session_state["lang"])
        reply = fn.chat_once(system_prompt, user_text, model=ct.OPENAI_MODEL)

        st.session_state["chat"].append(("assistant", reply))
        with st.chat_message("assistant"):
            st.write(reply)
            if st.session_state["lang"] == "ko":
                show_translation_if_needed(reply)

            if st.session_state.get("autoplay", False):
                synth_and_player(reply, st.session_state["lang"], file_stub="reply_new")
            else:
                if st.button("â–¶ï¸ å†ç”Ÿ", key=f"play_new_{len(st.session_state['chat'])}"):
                    synth_and_player(reply, st.session_state["lang"], file_stub="reply_new")

# ========== 2) Shadowing ==========
elif st.session_state["mode"] == ct.ANSWER_MODE_SHADOWING:
    st.subheader("Shadowingï¼ˆéŸ³èª­ãƒ»å¾©å”±ï¼‰")

    c1, c2, c3 = st.columns(3)
    with c1:
        level = st.selectbox("é›£æ˜“åº¦", ["easy", "normal", "hard"], index=0)
    with c2:
        repeat_n = st.number_input("å›æ•°ï¼ˆåŒã˜æ–‡ï¼‰", min_value=1, max_value=5, value=1, step=1)
    with c3:
        # éŒ²éŸ³æ‰‹æ®µã®é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ã¯ mic_recorderã€å‹•ã‹ãªã„ã¨ãã¯WebRTCï¼‰
        use_webrtc = st.toggle("WebRTCéŒ²éŸ³ï¼ˆãƒ™ãƒ¼ã‚¿ï¼‰ã‚’ä½¿ã†", value=False)

    sents = ct.SHADOWING_CORPUS_KO[level] if st.session_state["lang"] == "ko" else ct.SHADOWING_CORPUS_EN[level]
    st.markdown("#### ä¾‹æ–‡ï¼ˆ30ä»¶ï¼‰")
    st.markdown("<div class='scroll-list'><ol>" + "".join(f"<li>{s}</li>" for s in sents) + "</ol></div>", unsafe_allow_html=True)

    st.markdown("---")
    idx = st.number_input("ç·´ç¿’ã™ã‚‹æ–‡ç•ªå·", min_value=1, max_value=len(sents), value=1, step=1)
    target = sents[idx - 1]

    st.markdown("##### ç›®æ¨™æ–‡")
    st.markdown(f'<div class="block">{target}</div>', unsafe_allow_html=True)

    b1, b2, _ = st.columns(3)
    with b1:
        if st.button("â–¶ï¸ åˆæˆéŸ³å£°ã‚’å†ç”Ÿ"):
            synth_and_player(target, st.session_state["lang"], file_stub=f"shadow_{level}_{idx}")
    with b2:
        wav_bytes = None
        if not use_webrtc:
            mic = mic_recorder(start_prompt="ğŸ™ï¸ éŒ²éŸ³é–‹å§‹", stop_prompt="â¹ï¸ åœæ­¢",
                               just_once=True, use_container_width=True, key=f"mic_{level}_{idx}")
            if mic and "bytes" in mic:
                wav_bytes = mic["bytes"]
        else:
            wav_bytes = record_audio_webrtc_once()

    if wav_bytes:
        recognizer = sr.Recognizer()
        try:
            with sr.AudioFile(io.BytesIO(wav_bytes)) as source:
                audio = recognizer.record(source)
            transcribed = fn.stt_recognize_from_audio(audio, lang_code=st.session_state["lang"])
        except Exception:
            transcribed = ""

        st.markdown("##### ã‚ãªãŸã®ç™ºè©±ï¼ˆSTTï¼‰")
        st.write(transcribed if transcribed else "(èãå–ã‚Œã¾ã›ã‚“ã§ã—ãŸ)")

        ref = fn.normalize_for_compare(target)
        got = fn.normalize_for_compare(transcribed)
        ratio = difflib.SequenceMatcher(None, ref, got).ratio()
        score = int(ratio * 100)
        st.markdown(f"**ã‚¹ã‚³ã‚¢ï¼š{score} / 100**")

        if st.session_state["lang"] == "ko":
            st.markdown("##### æ„å‘³ï¼ˆå‚è€ƒï¼‰")
            show_translation_if_needed(target)

        if repeat_n > 1:
            st.info(f"åŒã˜æ–‡ã‚’ {repeat_n} å›ç·´ç¿’ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚")

# ========== 3) Roleplay ==========
elif st.session_state["mode"] == ct.ANSWER_MODE_ROLEPLAY:
    st.subheader("Roleplayï¼ˆéŸ“å›½èªã‚·ãƒŠãƒªã‚ªï¼‰")

    labels = [x["label"] for x in ct.ROLEPLAY_SCENARIOS_KO]
    idx = st.selectbox("ã‚·ãƒŠãƒªã‚ª", list(range(len(labels))), format_func=lambda i: labels[i], index=0)
    scenario = ct.ROLEPLAY_SCENARIOS_KO[idx]

    key = f"rp_{scenario['key']}"
    if key not in st.session_state:
        st.session_state[key] = []

    with st.expander("ã‚·ãƒŠãƒªã‚ªé–‹å§‹ä¾‹ï¼ˆéŸ“å›½èªï¼‰", expanded=False):
        st.markdown(f"- ä¾‹: {scenario['opening_user_ko']}")

    for i, (who, text) in enumerate(st.session_state[key]):
        with st.chat_message(who):
            st.write(text)
            if who == "assistant":
                show_translation_if_needed(text)
                if st.button("â–¶ï¸ å†ç”Ÿ", key=f"play_rp_hist_{i}"):
                    synth_and_player(text, "ko", file_stub=f"rp_{scenario['key']}_{i}")

    user_text = st.chat_input("ã‚»ãƒªãƒ•ã‚’å…¥åŠ›ï¼ˆæ—¥æœ¬èª/éŸ“å›½èªï¼‰")
    if user_text:
        st.session_state[key].append(("user", user_text))
        with st.chat_message("user"):
            st.write(user_text)

        system_base = ct.system_prompt_for(ct.ANSWER_MODE_ROLEPLAY, "ko")
        system_prompt = scenario["system_prompt"] + "\n" + system_base

        reply = fn.chat_once(system_prompt, user_text, model=ct.OPENAI_MODEL)
        st.session_state[key].append(("assistant", reply))
        with st.chat_message("assistant"):
            st.write(reply)
            show_translation_if_needed(reply)

            if st.session_state.get("autoplay", False):
                synth_and_player(reply, "ko", file_stub=f"rp_{scenario['key']}_new")
            else:
                if st.button("â–¶ï¸ å†ç”Ÿ", key=f"play_rp_new_{len(st.session_state[key])}"):
                    synth_and_player(reply, "ko", file_stub=f"rp_{scenario['key']}_new")
